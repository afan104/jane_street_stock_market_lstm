{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyarrow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access data\n",
    "parquet_file = 'data/jane-street-real-time-market-data-forecasting/train.parquet/partition_id=0/part-0.parquet'\n",
    "df = pd.read_parquet(parquet_file, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine date_id and time_id to create a time-based sequence variable\n",
    "shrink = 10000\n",
    "id = (df['date_id']/shrink)*(max(df['time_id'])+1) + df['time_id']/shrink # the base is max(df['time_id'])+1; similar to base 10 system\n",
    "df['seq_id'] = id\n",
    "df = df.reindex(columns=['seq_id'] + list(df.columns[:-1]))\n",
    "df.drop(columns=['date_id', 'time_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_0</th>\n",
       "      <th>responder_1</th>\n",
       "      <th>responder_2</th>\n",
       "      <th>responder_3</th>\n",
       "      <th>responder_4</th>\n",
       "      <th>responder_5</th>\n",
       "      <th>responder_6</th>\n",
       "      <th>responder_7</th>\n",
       "      <th>responder_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.889038</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.465815</td>\n",
       "      <td>0.514922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066075</td>\n",
       "      <td>0.573849</td>\n",
       "      <td>0.493044</td>\n",
       "      <td>0.638087</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.518602</td>\n",
       "      <td>0.621837</td>\n",
       "      <td>0.577598</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>0.509550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.370613</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.459389</td>\n",
       "      <td>0.513077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065630</td>\n",
       "      <td>0.796589</td>\n",
       "      <td>0.619008</td>\n",
       "      <td>0.447600</td>\n",
       "      <td>0.884992</td>\n",
       "      <td>0.762698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.570367</td>\n",
       "      <td>0.521668</td>\n",
       "      <td>0.577864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.285698</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.473393</td>\n",
       "      <td>0.513791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069997</td>\n",
       "      <td>0.413551</td>\n",
       "      <td>0.471970</td>\n",
       "      <td>0.467330</td>\n",
       "      <td>0.537578</td>\n",
       "      <td>0.627129</td>\n",
       "      <td>0.509979</td>\n",
       "      <td>0.710935</td>\n",
       "      <td>0.567088</td>\n",
       "      <td>0.577283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.690606</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.515538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065762</td>\n",
       "      <td>0.540850</td>\n",
       "      <td>0.522399</td>\n",
       "      <td>0.729489</td>\n",
       "      <td>0.609744</td>\n",
       "      <td>0.622587</td>\n",
       "      <td>0.622538</td>\n",
       "      <td>0.611414</td>\n",
       "      <td>0.577520</td>\n",
       "      <td>0.362048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.440570</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.469661</td>\n",
       "      <td>0.515316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144631</td>\n",
       "      <td>0.462661</td>\n",
       "      <td>0.449724</td>\n",
       "      <td>0.465198</td>\n",
       "      <td>0.107185</td>\n",
       "      <td>0.340863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142718</td>\n",
       "      <td>0.391088</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id  symbol_id    weight  feature_00  feature_01  feature_02  \\\n",
       "0     0.0          1  3.889038        -1.0        -1.0        -1.0   \n",
       "1     0.0          7  1.370613        -1.0        -1.0        -1.0   \n",
       "2     0.0          9  2.285698        -1.0        -1.0        -1.0   \n",
       "3     0.0         10  0.690606        -1.0        -1.0        -1.0   \n",
       "4     0.0         14  0.440570        -1.0        -1.0        -1.0   \n",
       "\n",
       "   feature_03  feature_04  feature_05  feature_06  ...  feature_78  \\\n",
       "0        -1.0        -1.0    0.465815    0.514922  ...    0.066075   \n",
       "1        -1.0        -1.0    0.459389    0.513077  ...    0.065630   \n",
       "2        -1.0        -1.0    0.473393    0.513791  ...    0.069997   \n",
       "3        -1.0        -1.0    0.476461    0.515538  ...    0.065762   \n",
       "4        -1.0        -1.0    0.469661    0.515316  ...    0.144631   \n",
       "\n",
       "   responder_0  responder_1  responder_2  responder_3  responder_4  \\\n",
       "0     0.573849     0.493044     0.638087     0.700535     0.518602   \n",
       "1     0.796589     0.619008     0.447600     0.884992     0.762698   \n",
       "2     0.413551     0.471970     0.467330     0.537578     0.627129   \n",
       "3     0.540850     0.522399     0.729489     0.609744     0.622587   \n",
       "4     0.462661     0.449724     0.465198     0.107185     0.340863   \n",
       "\n",
       "   responder_5  responder_6  responder_7  responder_8  \n",
       "0     0.621837     0.577598     0.534700     0.509550  \n",
       "1     1.000000     0.570367     0.521668     0.577864  \n",
       "2     0.509979     0.710935     0.567088     0.577283  \n",
       "3     0.622538     0.611414     0.577520     0.362048  \n",
       "4     0.000000     0.142718     0.391088     0.000000  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize and impute NaN with -1 after min/max norm\n",
    "def minmax_neg1nan(df):\n",
    "    # Find the columns not containing \"id\" in their name\n",
    "    norm_columns = [col for col in df.columns if \"id\" not in col]\n",
    "    norm_columns.remove('weight') # probably good to keep weight as is\n",
    "\n",
    "    # Min-Max Normalisation to [0,1] for non-id nor weight columns\n",
    "    df[norm_columns] = df[norm_columns].apply(lambda col: (col - col.min()) / (col.max() - col.min()))\n",
    "\n",
    "    # fill NaN values with -1\n",
    "    df.fillna(-1, inplace=True)\n",
    "\n",
    "    return df\n",
    "df = minmax_neg1nan(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_00</th>\n",
       "      <th>feature_01</th>\n",
       "      <th>feature_02</th>\n",
       "      <th>feature_03</th>\n",
       "      <th>feature_04</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_70</th>\n",
       "      <th>feature_71</th>\n",
       "      <th>feature_72</th>\n",
       "      <th>feature_73</th>\n",
       "      <th>feature_74</th>\n",
       "      <th>feature_75</th>\n",
       "      <th>feature_76</th>\n",
       "      <th>feature_77</th>\n",
       "      <th>feature_78</th>\n",
       "      <th>responder_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.889038</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.465815</td>\n",
       "      <td>0.514922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010971</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.081308</td>\n",
       "      <td>0.078341</td>\n",
       "      <td>0.066610</td>\n",
       "      <td>0.066075</td>\n",
       "      <td>0.577598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.370613</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.459389</td>\n",
       "      <td>0.513077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010513</td>\n",
       "      <td>0.002409</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.080878</td>\n",
       "      <td>0.078968</td>\n",
       "      <td>0.068394</td>\n",
       "      <td>0.065630</td>\n",
       "      <td>0.570367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.285698</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.473393</td>\n",
       "      <td>0.513791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013406</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.005881</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.095183</td>\n",
       "      <td>0.089571</td>\n",
       "      <td>0.071146</td>\n",
       "      <td>0.069997</td>\n",
       "      <td>0.710935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.690606</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.515538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.032793</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>0.077466</td>\n",
       "      <td>0.068990</td>\n",
       "      <td>0.065762</td>\n",
       "      <td>0.611414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.440570</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.469661</td>\n",
       "      <td>0.515316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.166908</td>\n",
       "      <td>0.144226</td>\n",
       "      <td>0.125198</td>\n",
       "      <td>0.144631</td>\n",
       "      <td>0.142718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id  symbol_id    weight  feature_00  feature_01  feature_02  \\\n",
       "0     0.0          1  3.889038        -1.0        -1.0        -1.0   \n",
       "1     0.0          7  1.370613        -1.0        -1.0        -1.0   \n",
       "2     0.0          9  2.285698        -1.0        -1.0        -1.0   \n",
       "3     0.0         10  0.690606        -1.0        -1.0        -1.0   \n",
       "4     0.0         14  0.440570        -1.0        -1.0        -1.0   \n",
       "\n",
       "   feature_03  feature_04  feature_05  feature_06  ...  feature_70  \\\n",
       "0        -1.0        -1.0    0.465815    0.514922  ...    0.010971   \n",
       "1        -1.0        -1.0    0.459389    0.513077  ...    0.010513   \n",
       "2        -1.0        -1.0    0.473393    0.513791  ...    0.013406   \n",
       "3        -1.0        -1.0    0.476461    0.515538  ...    0.018484   \n",
       "4        -1.0        -1.0    0.469661    0.515316  ...    0.009153   \n",
       "\n",
       "   feature_71  feature_72  feature_73  feature_74  feature_75  feature_76  \\\n",
       "0    0.005625    0.006320        -1.0        -1.0    0.081308    0.078341   \n",
       "1    0.002409    0.005603        -1.0        -1.0    0.080878    0.078968   \n",
       "2    0.003304    0.005881        -1.0        -1.0    0.095183    0.089571   \n",
       "3    0.032793    0.017134        -1.0        -1.0    0.082058    0.077466   \n",
       "4    0.005315    0.006302        -1.0        -1.0    0.166908    0.144226   \n",
       "\n",
       "   feature_77  feature_78  responder_6  \n",
       "0    0.066610    0.066075     0.577598  \n",
       "1    0.068394    0.065630     0.570367  \n",
       "2    0.071146    0.069997     0.710935  \n",
       "3    0.068990    0.065762     0.611414  \n",
       "4    0.125198    0.144631     0.142718  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop responders (other than responder 6) from df\n",
    "df.drop(columns=[f\"responder_{i}\" for i in [0,1,2,3,4,5,7,8]], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a subset of 10 features with closest simarility to the target: responder 6\n",
    "def subset_features(df, n):\n",
    "    corr_list = []\n",
    "    n_cols = df.shape[1]\n",
    "    x = df[\"responder_6\"]\n",
    "    for i in tqdm(range(3, n_cols-1)): # exclude responder 6 at end\n",
    "        y = df.iloc[:, i] # column i\n",
    "        mask = ~np.isnan(x) & ~np.isnan(y) # mask out NaN values\n",
    "        corr = np.nan if len(y[mask]) < 2 else abs(pearsonr(x[mask], y[mask]).correlation)\n",
    "        corr_list.append(tuple([i, corr]))\n",
    "\n",
    "    # sort column indices by most -> least correlated, take top n\n",
    "    out_tuple = sorted(\n",
    "        corr_list,\n",
    "        key=lambda x: (np.isnan(x[1]), -x[1] if not np.isnan(x[1]) else float(\"-inf\")),\n",
    "        reverse=False,\n",
    "    )[:n]\n",
    "\n",
    "    out = [x[0] for x in out_tuple]\n",
    "\n",
    "    return sorted(out) # return in index order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456d6b771f9f41c2a9c17715adbf57c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/78671977.py:9: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr = np.nan if len(y[mask]) < 2 else abs(pearsonr(x[mask], y[mask]).correlation)\n"
     ]
    }
   ],
   "source": [
    "subset_n = 10\n",
    "subset_columns = [0,1,2] + subset_features(df, n=subset_n) + [df.columns.get_loc(\"responder_6\")]\n",
    "\n",
    "split_ratio = 0.8\n",
    "train_df = df.iloc[:int(len(df)*split_ratio), subset_columns]\n",
    "test_df = df.iloc[int(len(df)*split_ratio):, subset_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>responder_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.889038</td>\n",
       "      <td>0.465815</td>\n",
       "      <td>0.514922</td>\n",
       "      <td>0.425142</td>\n",
       "      <td>0.279095</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.449066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.264526</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0.010717</td>\n",
       "      <td>0.577598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.370613</td>\n",
       "      <td>0.459389</td>\n",
       "      <td>0.513077</td>\n",
       "      <td>0.423677</td>\n",
       "      <td>0.281537</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.544227</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.338956</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.570367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2.285698</td>\n",
       "      <td>0.473393</td>\n",
       "      <td>0.513791</td>\n",
       "      <td>0.424863</td>\n",
       "      <td>0.246460</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.481614</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.234111</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>0.008997</td>\n",
       "      <td>0.710935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.690606</td>\n",
       "      <td>0.476461</td>\n",
       "      <td>0.515538</td>\n",
       "      <td>0.426033</td>\n",
       "      <td>0.350599</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.666179</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.410094</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.611414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.440570</td>\n",
       "      <td>0.469661</td>\n",
       "      <td>0.515316</td>\n",
       "      <td>0.426816</td>\n",
       "      <td>0.290998</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.552196</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.414646</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.142718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seq_id  symbol_id    weight  feature_05  feature_06  feature_07  \\\n",
       "0     0.0          1  3.889038    0.465815    0.514922    0.425142   \n",
       "1     0.0          7  1.370613    0.459389    0.513077    0.423677   \n",
       "2     0.0          9  2.285698    0.473393    0.513791    0.424863   \n",
       "3     0.0         10  0.690606    0.476461    0.515538    0.426033   \n",
       "4     0.0         14  0.440570    0.469661    0.515316    0.426816   \n",
       "\n",
       "   feature_19  feature_39  feature_51  feature_53  feature_56  feature_68  \\\n",
       "0    0.279095        -1.0    0.449066        -1.0    0.264526    0.002818   \n",
       "1    0.281537        -1.0    0.544227        -1.0    0.338956    0.003411   \n",
       "2    0.246460        -1.0    0.481614        -1.0    0.234111    0.002999   \n",
       "3    0.350599        -1.0    0.666179        -1.0    0.410094    0.008494   \n",
       "4    0.290998        -1.0    0.552196        -1.0    0.414646    0.002691   \n",
       "\n",
       "   feature_69  responder_6  \n",
       "0    0.010717     0.577598  \n",
       "1    0.009337     0.570367  \n",
       "2    0.008997     0.710935  \n",
       "3    0.014574     0.611414  \n",
       "4    0.011307     0.142718  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>symbol_id</th>\n",
       "      <th>weight</th>\n",
       "      <th>feature_05</th>\n",
       "      <th>feature_06</th>\n",
       "      <th>feature_07</th>\n",
       "      <th>feature_19</th>\n",
       "      <th>feature_39</th>\n",
       "      <th>feature_51</th>\n",
       "      <th>feature_53</th>\n",
       "      <th>feature_56</th>\n",
       "      <th>feature_68</th>\n",
       "      <th>feature_69</th>\n",
       "      <th>responder_6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1555368</th>\n",
       "      <td>12.1925</td>\n",
       "      <td>33</td>\n",
       "      <td>1.301134</td>\n",
       "      <td>0.439631</td>\n",
       "      <td>0.511814</td>\n",
       "      <td>0.423044</td>\n",
       "      <td>0.494335</td>\n",
       "      <td>0.256487</td>\n",
       "      <td>0.450238</td>\n",
       "      <td>0.522075</td>\n",
       "      <td>0.495673</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.516518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555369</th>\n",
       "      <td>12.1925</td>\n",
       "      <td>34</td>\n",
       "      <td>1.437518</td>\n",
       "      <td>0.440414</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>0.422065</td>\n",
       "      <td>0.485144</td>\n",
       "      <td>0.595078</td>\n",
       "      <td>0.339397</td>\n",
       "      <td>0.573141</td>\n",
       "      <td>0.556594</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.428489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555370</th>\n",
       "      <td>12.1925</td>\n",
       "      <td>38</td>\n",
       "      <td>1.926398</td>\n",
       "      <td>0.438835</td>\n",
       "      <td>0.511766</td>\n",
       "      <td>0.421562</td>\n",
       "      <td>0.252044</td>\n",
       "      <td>0.473257</td>\n",
       "      <td>0.214426</td>\n",
       "      <td>0.557326</td>\n",
       "      <td>0.486511</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>0.456160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555371</th>\n",
       "      <td>12.1926</td>\n",
       "      <td>0</td>\n",
       "      <td>2.116013</td>\n",
       "      <td>0.442453</td>\n",
       "      <td>0.515137</td>\n",
       "      <td>0.422550</td>\n",
       "      <td>0.516998</td>\n",
       "      <td>0.387863</td>\n",
       "      <td>0.438227</td>\n",
       "      <td>0.588736</td>\n",
       "      <td>0.511437</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.011333</td>\n",
       "      <td>0.463442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555372</th>\n",
       "      <td>12.1926</td>\n",
       "      <td>1</td>\n",
       "      <td>3.343626</td>\n",
       "      <td>0.440680</td>\n",
       "      <td>0.512819</td>\n",
       "      <td>0.422627</td>\n",
       "      <td>0.445221</td>\n",
       "      <td>0.369758</td>\n",
       "      <td>0.239692</td>\n",
       "      <td>0.550703</td>\n",
       "      <td>0.574810</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.545143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          seq_id  symbol_id    weight  feature_05  feature_06  feature_07  \\\n",
       "1555368  12.1925         33  1.301134    0.439631    0.511814    0.423044   \n",
       "1555369  12.1925         34  1.437518    0.440414    0.512207    0.422065   \n",
       "1555370  12.1925         38  1.926398    0.438835    0.511766    0.421562   \n",
       "1555371  12.1926          0  2.116013    0.442453    0.515137    0.422550   \n",
       "1555372  12.1926          1  3.343626    0.440680    0.512819    0.422627   \n",
       "\n",
       "         feature_19  feature_39  feature_51  feature_53  feature_56  \\\n",
       "1555368    0.494335    0.256487    0.450238    0.522075    0.495673   \n",
       "1555369    0.485144    0.595078    0.339397    0.573141    0.556594   \n",
       "1555370    0.252044    0.473257    0.214426    0.557326    0.486511   \n",
       "1555371    0.516998    0.387863    0.438227    0.588736    0.511437   \n",
       "1555372    0.445221    0.369758    0.239692    0.550703    0.574810   \n",
       "\n",
       "         feature_68  feature_69  responder_6  \n",
       "1555368    0.001625    0.009133     0.516518  \n",
       "1555369    0.001830    0.009276     0.428489  \n",
       "1555370    0.001676    0.008339     0.456160  \n",
       "1555371    0.001664    0.011333     0.463442  \n",
       "1555372    0.001880    0.010765     0.545143  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reformat Data to Multiple Tensors for Pickeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:22: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/3123175601.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  symbol_df = symbol_df.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "symbols = train_df['symbol_id'].unique() # based on train symbols\n",
    "symbols.sort()\n",
    "\n",
    "seq_ids_train = train_df['seq_id'].unique()\n",
    "seq_ids_test = test_df['seq_id'].unique()\n",
    "\n",
    "def create_tensor_from_df(df, seq_ids, sym):\n",
    "    # filter for symbol\n",
    "    symbol_df = df[df.symbol_id==sym]\n",
    "\n",
    "    # Add additional rows for all seq_ids that are missing\n",
    "    missing_seq_ids = np.setdiff1d(seq_ids, symbol_df.seq_id.unique())\n",
    "    missing_rows = pd.DataFrame({\n",
    "        'seq_id': missing_seq_ids, \n",
    "        'symbol_id': [sym]*len(missing_seq_ids),\n",
    "        })\n",
    "    for col in df.columns:\n",
    "        if col not in missing_rows.columns:\n",
    "            missing_rows[col] = np.nan\n",
    "\n",
    "    # Horizontally concatenate the two DataFrames\n",
    "    symbol_df = pd.concat([symbol_df, missing_rows], axis=0, ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame by 'seq_id' to maintain order\n",
    "    symbol_df = symbol_df.sort_values(by='seq_id').reset_index(drop=True)\n",
    "    \n",
    "    # Impute NaNs with the previous values\n",
    "    symbol_df.iloc[0] = symbol_df.iloc[0].fillna(-1) # fill first nan values with -1\n",
    "    symbol_df = symbol_df.fillna(method='ffill')\n",
    "\n",
    "    # Extract feature columns -> np.arrays\n",
    "    n_cols = symbol_df.shape[1]\n",
    "    features_arrs = []\n",
    "    for i in range(2, n_cols): # exclude seq_id and symbol_id\n",
    "        arr = symbol_df.iloc[:,i].to_numpy()\n",
    "        features_arrs.append(arr)\n",
    "\n",
    "    # stack into a tensor\n",
    "    stacked_features = np.column_stack(features_arrs)\n",
    "    tensor_features = torch.tensor(stacked_features)\n",
    "    \n",
    "    return tensor_features\n",
    "\n",
    "\n",
    "for sym in symbols:\n",
    "    train_tensor_features = create_tensor_from_df(train_df, seq_ids_train, sym)\n",
    "    test_tensor_features = create_tensor_from_df(test_df, seq_ids_test, sym)\n",
    "\n",
    "    # pickle and save\n",
    "    f_train = f\"./data/pickled_data/symbol{sym}_train.pt\"\n",
    "    f_test = f\"./data/pickled_data/symbol{sym}_test.pt\"\n",
    "    torch.save(train_tensor_features, f_train)\n",
    "    torch.save(test_tensor_features, f_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a residual MLP block (same as before)\n",
    "class ResBlockMLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ResBlockMLP, self).__init__()\n",
    "        self.norm1 = nn.LayerNorm(input_size)\n",
    "        self.fc1 = nn.Linear(input_size, input_size // 2)\n",
    "        self.norm2 = nn.LayerNorm(input_size // 2)\n",
    "        self.fc2 = nn.Linear(input_size // 2, output_size)\n",
    "        self.fc_skip = nn.Linear(input_size, output_size)\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # overall structure: input -> norm -> act -> skip\n",
    "        #                    input -> norm -> act -> fc1 -> norm -> act -> fc2\n",
    "        #                    return skip + fc2\n",
    "        x = self.act(self.norm1(x))\n",
    "        skip = self.fc_skip(x)\n",
    "        x = self.fc2(self.act(self.norm2(self.fc1(x))))\n",
    "        return x + skip\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, seq_len, n_cols, seq_len_out, num_blocks=1, hidden_size = 128): # NOTE: removed buffer_size arg from RNN class\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        # calculate sequence length after flatten\n",
    "        seq_data_len = seq_len * n_cols\n",
    "\n",
    "        # Same as with mlp before\n",
    "        self.input_mlp = nn.Sequential(\n",
    "            nn.Linear(seq_data_len, 4 * seq_data_len),\n",
    "            nn.ELU(),  \n",
    "            nn.Linear(4 * seq_data_len, hidden_size) \n",
    "        )\n",
    "\n",
    "        # Define LSTM block\n",
    "        self.lstm = nn.LSTM(input_size = hidden_size, hidden_size = hidden_size, num_layers = num_blocks, batch_first=True) \n",
    "\n",
    "        blocks = [ResBlockMLP(hidden_size, hidden_size) for _ in range(num_blocks)]\n",
    "        self.res_blocks = nn.Sequential(*blocks)\n",
    "        self.fc_out = nn.Linear(hidden_size, seq_len_out) # this is for output\n",
    "        self.act = nn.ELU()\n",
    "\n",
    "    def forward(self, input_seq, hidden_in, mem_in):\n",
    "        # flatten\n",
    "        B,_,_ = input_seq.shape\n",
    "        input_seq = torch.reshape(input_seq, (B, -1))\n",
    "\n",
    "        # Pass through MLP\n",
    "        input_vec = self.input_mlp(input_seq)\n",
    "        input_vec = input_vec.unsqueeze(1)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        output, (hidden_out, mem_out) = self.lstm(input_vec, (hidden_in, mem_in))\n",
    "\n",
    "        # Pass LSTM output through residual blocks\n",
    "        x = self.act(self.res_blocks(output)).squeeze(0)\n",
    "\n",
    "        # Compute the final output\n",
    "        return self.fc_out(x), hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, f, seq_len=100):\n",
    "        self.seq_len = seq_len\n",
    "        self.data = torch.load(f)\n",
    "    def __len__(self): # number input output combos\n",
    "        return len(self.data) - self.seq_len\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx:idx+self.seq_len,:11] # 1 to 11\n",
    "        y = self.data[idx+self.seq_len,11] # column 12\n",
    "        return x, y\n",
    "\n",
    "def get_dataloader(f, seq_len=100, batch_size=32):\n",
    "    dataset = StockDataset(f, seq_len)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for symbol 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/17/363kc2_n4bdg1h6hdx82d81h0000gn/T/ipykernel_75150/2952213254.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data = torch.load(f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618352b8fb284617a6a80b3282c4ef7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyfan/kaggle/.venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed9387d28e446b9a263d342976b0fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amyfan/kaggle/.venv/lib/python3.11/site-packages/torch/nn/modules/loss.py:608: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 0, Train Loss: 0.3496879041194916\n",
      "Epoch 1, Symbol 0, Test Loss: 1.0615185678774863\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902a09a5000947f4b02646c34470a6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 0, Train Loss: 0.005025885067880154\n",
      "Epoch 952, Symbol 0, Test Loss: 0.007369507842735952\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cef6fbd2d44384ae9d672e6ed0a2a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 0, Train Loss: 0.0793580487370491\n",
      "Epoch 1903, Symbol 0, Test Loss: 0.006814557665636979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1357f62c08294c7d9b17ec5421355f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 0, Train Loss: 0.002839675871655345\n",
      "Epoch 2854, Symbol 0, Test Loss: 0.00774073179652901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2b0cef10c743a3803887731d66b745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Symbol 0, Train Loss: 0.003555622883141041\n",
      "Epoch 3805, Symbol 0, Test Loss: 0.00679251238926871\n",
      "Training for symbol 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4172ced942394d1bb35f1a7938b62e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b37100ee9744f5f8c48b8636c40da11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 1, Train Loss: 0.005826271139085293\n",
      "Epoch 1, Symbol 1, Test Loss: 0.005648885053379389\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0969ee27719f4f7385b1e917e3dddced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 1, Train Loss: 0.0041917660273611546\n",
      "Epoch 952, Symbol 1, Test Loss: 0.005425619958416216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91400e65356442cfa60b58acf2a7cbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 1, Train Loss: 0.005741640459746122\n",
      "Epoch 1903, Symbol 1, Test Loss: 0.005342391260112589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e1023897eb439c899f6f17110593fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 1, Train Loss: 0.0037733367644250393\n",
      "Epoch 2854, Symbol 1, Test Loss: 0.005313063693103224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ccedd86f0b2418884a33d4cd8a06d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Symbol 1, Train Loss: 0.0011915079085156322\n",
      "Epoch 3805, Symbol 1, Test Loss: 0.00528441931918087\n",
      "Training for symbol 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b2fc09dab54d8a9ee4a5514d8a1148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af70383627a4b1da3a5d1f1337a6254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 2, Train Loss: 0.01484135165810585\n",
      "Epoch 1, Symbol 2, Test Loss: 0.009312709163269095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a355f1ba5b48fbaec1cc6addf31263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 2, Train Loss: 0.07874444872140884\n",
      "Epoch 952, Symbol 2, Test Loss: 0.009620834024051148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23328a3274a47c79b5dc1bf9e2a5037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 2, Train Loss: 0.0013705973979085684\n",
      "Epoch 1903, Symbol 2, Test Loss: 0.009380594242986831\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93fa17566e244f94875bc335783a9d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 2, Train Loss: 0.0021086479537189007\n",
      "Epoch 2854, Symbol 2, Test Loss: 0.009907079135686416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9102b6832a0545aa99d0e938d544a7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Symbol 2, Train Loss: 0.07014008611440659\n",
      "Epoch 3805, Symbol 2, Test Loss: 0.01047717292400256\n",
      "Training for symbol 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eb2dfd0fa348b49144307b4738b9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5801f882ea04ebcb3285a8ebe260027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 3, Train Loss: 0.003249447327107191\n",
      "Epoch 1, Symbol 3, Test Loss: 0.03565558918632856\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d457c32537be4bbdbe27bfa6ef53053a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 3, Train Loss: 0.0740150585770607\n",
      "Epoch 952, Symbol 3, Test Loss: 0.03582662921078193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4ab66f1d514a5897bb4cdfdd51124e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 3, Train Loss: 0.007413134910166264\n",
      "Epoch 1903, Symbol 3, Test Loss: 0.03650569295613536\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87760ae663f5465cb3d816fcfe0172d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 3, Train Loss: 0.07239172607660294\n",
      "Epoch 2854, Symbol 3, Test Loss: 0.035998744663276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923549420c3943739f608f507ac3a601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Symbol 3, Train Loss: 0.08008686453104019\n",
      "Epoch 3805, Symbol 3, Test Loss: 0.0352789427516541\n",
      "Training for symbol 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6d118e07a24fb4a1006da63c900325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35adf39e00064e6c9c014b5dc63dfc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 7, Train Loss: 0.007712051272392273\n",
      "Epoch 1, Symbol 7, Test Loss: 0.010356634729668777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea32bcd03874ae3a4e1686efc948234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 7, Train Loss: 0.004461636766791344\n",
      "Epoch 952, Symbol 7, Test Loss: 0.010172700270418469\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce044166aa90445299fe7d10c0aa5b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 7, Train Loss: 0.011262756772339344\n",
      "Epoch 1903, Symbol 7, Test Loss: 0.010463269007855885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f706361494bc4678baaf8a3018e311a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 7, Train Loss: 0.009641147218644619\n",
      "Epoch 2854, Symbol 7, Test Loss: 0.010139608630440177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494669d408e14d03b0a1494242a734a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Symbol 7, Train Loss: 0.0030413770582526922\n",
      "Epoch 3805, Symbol 7, Test Loss: 0.010598228050468\n",
      "Training for symbol 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f72e3bc56c14fedb734223890b5fb48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7decdcaa16b940bd8b89e6ae8339b33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 8, Train Loss: 0.21969705820083618\n",
      "Epoch 1, Symbol 8, Test Loss: 0.009108831500367313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1aa2713479942bbaca448ea6b858eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 8, Train Loss: 0.1392022967338562\n",
      "Epoch 952, Symbol 8, Test Loss: 0.011079103584699278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb62f84d8ba4d599692b8de2c614348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 8, Train Loss: 0.07115951925516129\n",
      "Epoch 1903, Symbol 8, Test Loss: 0.009855938480079303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654e9ac3591f44088bdbc8f77efec28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 8, Train Loss: 0.14565755426883698\n",
      "Epoch 2854, Symbol 8, Test Loss: 0.010549391021917293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c89d957eee4b1a89ef8e72e3e40eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3805, Symbol 8, Train Loss: 0.13978978991508484\n",
      "Epoch 3805, Symbol 8, Test Loss: 0.00927901540437267\n",
      "Training for symbol 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e36265969e4920927efe589f23c4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epochs:   0%|          | 0/3807 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0424aefa6e4f9c9f34947a5549a7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Symbol 9, Train Loss: 0.004346300382167101\n",
      "Epoch 1, Symbol 9, Test Loss: 0.0077054922559486975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d577d8101a024cf493b4296397a4a727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952, Symbol 9, Train Loss: 0.0022791295778006315\n",
      "Epoch 952, Symbol 9, Test Loss: 0.007868595959797737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f13e893fff410bb2a504545019e74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1903, Symbol 9, Train Loss: 0.0013499298365786672\n",
      "Epoch 1903, Symbol 9, Test Loss: 0.00769010665452367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d116b587f1e942fbbbfd91eec43d9434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test Epoch:   0%|          | 0/697 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2854, Symbol 9, Train Loss: 0.0031865923665463924\n",
      "Epoch 2854, Symbol 9, Test Loss: 0.007852083226061898\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "seq_len = 100 # train 100 rows at a time\n",
    "no_cols = subset_n + 1 # 10 features + 1 weight\n",
    "seq_out_size = 1 # predict 1 rows at a time\n",
    "batch_size = 32\n",
    "hidden_size = 128\n",
    "stock_lstm = LSTM(seq_len, no_cols, seq_out_size, hidden_size=hidden_size)\n",
    "\n",
    "# Define optimizer\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(stock_lstm.parameters(), lr=lr)\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "for sym in symbols:\n",
    "    print(\"Training for symbol\", sym)\n",
    "    # Load pickled data\n",
    "    f_train = f\"./data/pickled_data/symbol{sym}_train.pt\"\n",
    "    train_dataloader = get_dataloader(f_train, seq_len=seq_len, batch_size=batch_size)\n",
    "    train_dataloader_iterator = iter(train_dataloader)\n",
    "\n",
    "    epochs = len(train_dataloader) # Number of batches, i.e. Number of Examples / Batch Size\n",
    "    for epoch in tqdm(range(epochs), \"Training Epochs\"):\n",
    "\n",
    "        predictors_train, targets_train = next(train_dataloader_iterator)\n",
    "        targets_train = targets_train.unsqueeze(1)\n",
    "\n",
    "        # Define hidden and memory states\n",
    "        hidden_train = torch.zeros(1, batch_size, hidden_size)\n",
    "        memory_train = torch.zeros(1, batch_size, hidden_size)\n",
    "\n",
    "        # Train model\n",
    "        stock_lstm.train()\n",
    "        # forward pass\n",
    "        outputs_train, hidden_train_new, memory_train_new = stock_lstm(predictors_train, hidden_train, memory_train)\n",
    "\n",
    "        # calc loss\n",
    "        loss = loss_fn(outputs_train, targets_train)\n",
    "        # zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # loss backward\n",
    "        loss.backward()\n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Detach hidden and memory states\n",
    "        hidden_train = hidden_train_new.detach() # so version is 0 when backpropagating\n",
    "        memory_train = memory_train_new.detach()\n",
    "\n",
    "        if epoch % (epochs//4) == 0:            \n",
    "            # Test model\n",
    "            f_test = f\"./data/pickled_data/symbol{sym}_test.pt\"\n",
    "            test_dataloader = get_dataloader(f_test, seq_len=seq_len, batch_size=batch_size)\n",
    "            test_dataloader_iterator = iter(test_dataloader)\n",
    "\n",
    "            test_batch_count = len(test_dataloader)\n",
    "            stock_lstm.eval()\n",
    "            with torch.no_grad():\n",
    "                total_loss = 0\n",
    "                for test_epoch in tqdm(range(test_batch_count), \"Test Epoch\"):\n",
    "                    predictors_test, targets_test = next(test_dataloader_iterator)\n",
    "                    \n",
    "                    # Define hidden and memory states\n",
    "                    hidden_test = torch.zeros(1, batch_size, hidden_size)\n",
    "                    memory_test = torch.zeros(1, batch_size, hidden_size)\n",
    "\n",
    "                    outputs_test, hidden_test, memory_test = stock_lstm(predictors_test, hidden_test, memory_test)\n",
    "                    batch_test_loss = loss_fn(outputs_test, targets_test)\n",
    "                    total_loss += batch_test_loss.item()\n",
    "                test_loss = total_loss / test_batch_count\n",
    "                tqdm.write(f\"Epoch {epoch + 1}, Symbol {sym}, Train Loss: {loss.item()}\")\n",
    "                tqdm.write(f\"Epoch {epoch + 1}, Symbol {sym}, Test Loss: {test_loss}\")\n",
    "print(\"Done :)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
